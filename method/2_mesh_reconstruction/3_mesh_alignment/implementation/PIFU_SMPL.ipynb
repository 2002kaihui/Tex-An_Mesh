{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "from src.tf_smpl.smpl_with_inverse import SMPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting mesh vertices from .obj files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices(mesh_path, with_texture = False):\n",
    "    with open(mesh_path, \"r\") as f:\n",
    "        content = f.readlines()\n",
    "    vertices = [[np.float32(v_i) for v_i in v.split('\\n')[0].split(' ')[1:]] \n",
    "                for v in content if v.startswith('v ')]\n",
    "    vertices = np.array(vertices)\n",
    "    if with_texture:\n",
    "        return vertices\n",
    "    else:\n",
    "        return vertices[:,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aligning two sets of mesh-vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_verts_align(verts_1, verts_2, eps = 1e-8):\n",
    "    \"\"\"\n",
    "    this function aligns verts_2 to verts_1\n",
    "    verts_1, verts_2 are of shape (?,3)\n",
    "    \"\"\"\n",
    "    # finding bounding boxes\n",
    "    bbox_1_x_min, bbox_1_x_max = np.min(verts_1[:,0]), np.max(verts_1[:,0])\n",
    "    bbox_1_y_min, bbox_1_y_max = np.min(verts_1[:,1]), np.max(verts_1[:,1])\n",
    "    bbox_1_z_min, bbox_1_z_max = np.min(verts_1[:,2]), np.max(verts_1[:,2])\n",
    "    H1 = bbox_1_z_max - bbox_1_z_min\n",
    "    W1 = bbox_1_y_max - bbox_1_y_min\n",
    "    D1 = bbox_1_x_max - bbox_1_x_min\n",
    "    \n",
    "    bbox_2_x_min, bbox_2_x_max = np.min(verts_2[:,0]), np.max(verts_2[:,0])\n",
    "    bbox_2_y_min, bbox_2_y_max = np.min(verts_2[:,1]), np.max(verts_2[:,1])\n",
    "    bbox_2_z_min, bbox_2_z_max = np.min(verts_2[:,2]), np.max(verts_2[:,2])\n",
    "    H2 = bbox_2_z_max - bbox_2_z_min\n",
    "    W2 = bbox_2_y_max - bbox_2_y_min\n",
    "    D2 = bbox_2_x_max - bbox_2_x_min\n",
    "    \n",
    "    # get_centers\n",
    "    center_1 = 0.5* np.array([(bbox_1_x_min + bbox_1_x_max), \n",
    "                              (bbox_1_y_min + bbox_1_y_max),\n",
    "                              (bbox_1_z_min + bbox_1_z_max)])\n",
    "\n",
    "    center_2 = 0.5* np.array([(bbox_2_x_min + bbox_2_x_max), \n",
    "                              (bbox_2_y_min + bbox_2_y_max),\n",
    "                              (bbox_2_z_min + bbox_2_z_max)])\n",
    "    \n",
    "    verts_2 = verts_2 - center_2\n",
    "    verts_2[:,0] = verts_2[:,0]*(D1/D2+eps) \n",
    "    verts_2[:,1] = verts_2[:,1]*(W1/W2+eps)\n",
    "    verts_2[:,2] = verts_2[:,2]*(H1/H2+eps)\n",
    "    \n",
    "    verts_2 = verts_2 + center_1\n",
    "    \n",
    "    return verts_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving new vertices to .obj file with faces taken from the reference path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mesh_to_obj(new_verts, reference_path, save_path, textures=False):\n",
    "    with open(reference_path, \"r\") as f:\n",
    "        content = f.readlines()\n",
    "        lines = content#.split('\\n')\n",
    "        new_content = []\n",
    "        for i in tqdm(range(len(lines))):\n",
    "            line = lines[i]\n",
    "            if not line.startswith('v '):\n",
    "                new_line = line\n",
    "            else: \n",
    "                verts_part = ' '.join(line.split(' ')[:4])\n",
    "                if textures:\n",
    "                    new_line = line.replace(verts_part, 'v '+' '.join([str(val) for val in new_verts[i]]))\n",
    "                else:\n",
    "                    new_line = line.replace(verts_part, 'v '+' '.join([str(val) for val in new_verts[i]])+'\\n')\n",
    "            new_content.append(new_line)\n",
    "    new_content = ''.join(new_content)\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(new_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make an SMPL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/test/Desktop/hmr/src/tf_smpl/smpl_with_inverse.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/test/Desktop/hmr/src/tf_smpl/smpl_with_inverse.py:95: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/test/Desktop/hmr/src/tf_smpl/batch_lbs.py:53: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/test/Desktop/hmr/src/tf_smpl/smpl_with_inverse.py:100: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smpl = SMPL('/Users/test/Desktop/hmr/models/neutral_smpl_with_cocoplus_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pifu mesh vertices\n",
    "pifu_vertices = get_vertices('../../Downloads/result_levon.obj')\n",
    "\n",
    "# beta_and_theta_1\n",
    "theta_and_beta_1 = np.load('theta_and_beta_basketball.npy')\n",
    "theta_1, beta_1 = theta_and_beta_1[:,:72], theta_and_beta_1[:,72:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load smpl template from pickle\n",
    "with open('/Users/test/Desktop/hmr/models/neutral_smpl_with_cocoplus_reg.pkl', 'rb') as f:\n",
    "    dd = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blend_weights_for_smpl\n",
    "blend_weights_smpl = dd['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, these smpl vertices corresponds to the same image as pifu vertices\n",
    "smpl_vertices = smpl.predict_stright(beta_1, theta_1, blend_weights=blend_weights_smpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aligning pifu vertices to the corresponding smpl vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: in this special case we need to rotate the pifu mesh manually, but it may be useless in other cases.\n",
    "pifu_vertices_rotated =  pifu_vertices.copy()\n",
    "pifu_vertices_rotated[:,1] = -pifu_vertices_rotated[:,1]\n",
    "pifu_vertices_rotated[:,2] = -pifu_vertices_rotated[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning to the corresponding smpl vertices\n",
    "pifu_vertices_aligned = mesh_verts_align(smpl_vertices[0], pifu_vertices_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding blend weights for pifu mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_dist(A, B):\n",
    "    # squared norms of each row in A and B\n",
    "    na = np.sum(np.square(A), axis = 1)\n",
    "    nb = np.sum(np.square(B), axis =  1)\n",
    "\n",
    "    # na as a row and nb as a co\"lumn vectors\n",
    "    na = np.reshape(na, [-1, 1])\n",
    "    nb = np.reshape(nb, [1, -1])\n",
    "\n",
    "    # return pairwise euclidead difference matrix\n",
    "    D = np.maximum(na - 2*np.matmul(A, B.T) + nb, 0.0)\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.022251605987549\n"
     ]
    }
   ],
   "source": [
    "# for each vertex v in pifu_vertices find the closest vertex u in smpl_vertices and \n",
    "# put blend weights of v as the blend weights of u\n",
    "start = time()\n",
    "dists = pairwise_dist(pifu_vertices_aligned, smpl_vertices[0])\n",
    "print(time()-start)\n",
    "\n",
    "argmins = np.argmin(dists, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_weights_pifu = blend_weights_smpl[argmins]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the zero-pose (textured) mesh for pifu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pifu_vertices_zero_pose = smpl.predict_inverse(beta_1, theta_1, blend_weights=blend_weights_pifu, \n",
    "                                               binding_verts=pifu_vertices_aligned[None,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127500/127500 [00:00<00:00, 571899.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# save pifu zero pose to an .obj file\n",
    "save_mesh_to_obj(pifu_vertices_zero_pose[0], '../../Downloads/result_levon.obj',\n",
    "                save_path='pifu_zero_pose.obj', textures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move pifu mesh to the pose obtained from the parameters beta2, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pifu_mesh(pifu_zero_pose, ref_path='theta_and_beta_thenis.npy', blend_weights=None):\n",
    "    theta_and_beta = np.load(ref_path)\n",
    "    theta, beta = theta_and_beta[:,:72], theta_and_beta[:,72:]\n",
    "    pifu_result_vertices = smpl.predict_stright(beta, theta, blend_weights=blend_weights,\n",
    "                                                binding_verts=pifu_zero_pose)\n",
    "    return pifu_result_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pifu_result_vertices = get_pifu_mesh(pifu_vertices_zero_pose, blend_weights=blend_weights_pifu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127500/127500 [00:00<00:00, 579144.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# save pifu result pose to an .obj file\n",
    "save_mesh_to_obj(pifu_result_vertices[0], '../../Downloads/result_levon.obj',\n",
    "                save_path='pifu_thenis_pose.obj', textures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
